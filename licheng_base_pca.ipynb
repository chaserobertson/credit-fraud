{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime as dt\nimport tensorflow as tf\nimport math\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch.autograd import Variable ","metadata":{"execution":{"iopub.status.busy":"2022-08-16T07:21:17.472582Z","iopub.execute_input":"2022-08-16T07:21:17.473351Z","iopub.status.idle":"2022-08-16T07:21:28.744636Z","shell.execute_reply.started":"2022-08-16T07:21:17.473243Z","shell.execute_reply":"2022-08-16T07:21:28.743585Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('../input/creditcardfraud/creditcard.csv')\ndf.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-08-16T07:21:28.746517Z","iopub.execute_input":"2022-08-16T07:21:28.747112Z","iopub.status.idle":"2022-08-16T07:21:32.963584Z","shell.execute_reply.started":"2022-08-16T07:21:28.747076Z","shell.execute_reply":"2022-08-16T07:21:32.962376Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"Time      0\nV1        0\nV2        0\nV3        0\nV4        0\nV5        0\nV6        0\nV7        0\nV8        0\nV9        0\nV10       0\nV11       0\nV12       0\nV13       0\nV14       0\nV15       0\nV16       0\nV17       0\nV18       0\nV19       0\nV20       0\nV21       0\nV22       0\nV23       0\nV24       0\nV25       0\nV26       0\nV27       0\nV28       0\nAmount    0\nClass     0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-08-16T07:21:32.965280Z","iopub.execute_input":"2022-08-16T07:21:32.965988Z","iopub.status.idle":"2022-08-16T07:21:33.073685Z","shell.execute_reply.started":"2022-08-16T07:21:32.965942Z","shell.execute_reply":"2022-08-16T07:21:33.072461Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"            Time         V1         V2        V3        V4        V5  \\\n0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n...          ...        ...        ...       ...       ...       ...   \n284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n\n              V6        V7        V8        V9  ...       V21       V22  \\\n0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n...          ...       ...       ...       ...  ...       ...       ...   \n284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n\n             V23       V24       V25       V26       V27       V28  Amount  \\\n0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n...          ...       ...       ...       ...       ...       ...     ...   \n284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n\n        Class  \n0           0  \n1           0  \n2           0  \n3           0  \n4           0  \n...       ...  \n284802      0  \n284803      0  \n284804      0  \n284805      0  \n284806      0  \n\n[284807 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>-1.359807</td>\n      <td>-0.072781</td>\n      <td>2.536347</td>\n      <td>1.378155</td>\n      <td>-0.338321</td>\n      <td>0.462388</td>\n      <td>0.239599</td>\n      <td>0.098698</td>\n      <td>0.363787</td>\n      <td>...</td>\n      <td>-0.018307</td>\n      <td>0.277838</td>\n      <td>-0.110474</td>\n      <td>0.066928</td>\n      <td>0.128539</td>\n      <td>-0.189115</td>\n      <td>0.133558</td>\n      <td>-0.021053</td>\n      <td>149.62</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.191857</td>\n      <td>0.266151</td>\n      <td>0.166480</td>\n      <td>0.448154</td>\n      <td>0.060018</td>\n      <td>-0.082361</td>\n      <td>-0.078803</td>\n      <td>0.085102</td>\n      <td>-0.255425</td>\n      <td>...</td>\n      <td>-0.225775</td>\n      <td>-0.638672</td>\n      <td>0.101288</td>\n      <td>-0.339846</td>\n      <td>0.167170</td>\n      <td>0.125895</td>\n      <td>-0.008983</td>\n      <td>0.014724</td>\n      <td>2.69</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>-1.358354</td>\n      <td>-1.340163</td>\n      <td>1.773209</td>\n      <td>0.379780</td>\n      <td>-0.503198</td>\n      <td>1.800499</td>\n      <td>0.791461</td>\n      <td>0.247676</td>\n      <td>-1.514654</td>\n      <td>...</td>\n      <td>0.247998</td>\n      <td>0.771679</td>\n      <td>0.909412</td>\n      <td>-0.689281</td>\n      <td>-0.327642</td>\n      <td>-0.139097</td>\n      <td>-0.055353</td>\n      <td>-0.059752</td>\n      <td>378.66</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>-0.966272</td>\n      <td>-0.185226</td>\n      <td>1.792993</td>\n      <td>-0.863291</td>\n      <td>-0.010309</td>\n      <td>1.247203</td>\n      <td>0.237609</td>\n      <td>0.377436</td>\n      <td>-1.387024</td>\n      <td>...</td>\n      <td>-0.108300</td>\n      <td>0.005274</td>\n      <td>-0.190321</td>\n      <td>-1.175575</td>\n      <td>0.647376</td>\n      <td>-0.221929</td>\n      <td>0.062723</td>\n      <td>0.061458</td>\n      <td>123.50</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.0</td>\n      <td>-1.158233</td>\n      <td>0.877737</td>\n      <td>1.548718</td>\n      <td>0.403034</td>\n      <td>-0.407193</td>\n      <td>0.095921</td>\n      <td>0.592941</td>\n      <td>-0.270533</td>\n      <td>0.817739</td>\n      <td>...</td>\n      <td>-0.009431</td>\n      <td>0.798278</td>\n      <td>-0.137458</td>\n      <td>0.141267</td>\n      <td>-0.206010</td>\n      <td>0.502292</td>\n      <td>0.219422</td>\n      <td>0.215153</td>\n      <td>69.99</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>284802</th>\n      <td>172786.0</td>\n      <td>-11.881118</td>\n      <td>10.071785</td>\n      <td>-9.834783</td>\n      <td>-2.066656</td>\n      <td>-5.364473</td>\n      <td>-2.606837</td>\n      <td>-4.918215</td>\n      <td>7.305334</td>\n      <td>1.914428</td>\n      <td>...</td>\n      <td>0.213454</td>\n      <td>0.111864</td>\n      <td>1.014480</td>\n      <td>-0.509348</td>\n      <td>1.436807</td>\n      <td>0.250034</td>\n      <td>0.943651</td>\n      <td>0.823731</td>\n      <td>0.77</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>284803</th>\n      <td>172787.0</td>\n      <td>-0.732789</td>\n      <td>-0.055080</td>\n      <td>2.035030</td>\n      <td>-0.738589</td>\n      <td>0.868229</td>\n      <td>1.058415</td>\n      <td>0.024330</td>\n      <td>0.294869</td>\n      <td>0.584800</td>\n      <td>...</td>\n      <td>0.214205</td>\n      <td>0.924384</td>\n      <td>0.012463</td>\n      <td>-1.016226</td>\n      <td>-0.606624</td>\n      <td>-0.395255</td>\n      <td>0.068472</td>\n      <td>-0.053527</td>\n      <td>24.79</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>284804</th>\n      <td>172788.0</td>\n      <td>1.919565</td>\n      <td>-0.301254</td>\n      <td>-3.249640</td>\n      <td>-0.557828</td>\n      <td>2.630515</td>\n      <td>3.031260</td>\n      <td>-0.296827</td>\n      <td>0.708417</td>\n      <td>0.432454</td>\n      <td>...</td>\n      <td>0.232045</td>\n      <td>0.578229</td>\n      <td>-0.037501</td>\n      <td>0.640134</td>\n      <td>0.265745</td>\n      <td>-0.087371</td>\n      <td>0.004455</td>\n      <td>-0.026561</td>\n      <td>67.88</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>284805</th>\n      <td>172788.0</td>\n      <td>-0.240440</td>\n      <td>0.530483</td>\n      <td>0.702510</td>\n      <td>0.689799</td>\n      <td>-0.377961</td>\n      <td>0.623708</td>\n      <td>-0.686180</td>\n      <td>0.679145</td>\n      <td>0.392087</td>\n      <td>...</td>\n      <td>0.265245</td>\n      <td>0.800049</td>\n      <td>-0.163298</td>\n      <td>0.123205</td>\n      <td>-0.569159</td>\n      <td>0.546668</td>\n      <td>0.108821</td>\n      <td>0.104533</td>\n      <td>10.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>284806</th>\n      <td>172792.0</td>\n      <td>-0.533413</td>\n      <td>-0.189733</td>\n      <td>0.703337</td>\n      <td>-0.506271</td>\n      <td>-0.012546</td>\n      <td>-0.649617</td>\n      <td>1.577006</td>\n      <td>-0.414650</td>\n      <td>0.486180</td>\n      <td>...</td>\n      <td>0.261057</td>\n      <td>0.643078</td>\n      <td>0.376777</td>\n      <td>0.008797</td>\n      <td>-0.473649</td>\n      <td>-0.818267</td>\n      <td>-0.002415</td>\n      <td>0.013649</td>\n      <td>217.00</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>284807 rows × 31 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_fraud=df['Class']\n","metadata":{"execution":{"iopub.status.busy":"2022-08-16T07:21:33.076761Z","iopub.execute_input":"2022-08-16T07:21:33.077486Z","iopub.status.idle":"2022-08-16T07:21:33.085575Z","shell.execute_reply.started":"2022-08-16T07:21:33.077439Z","shell.execute_reply":"2022-08-16T07:21:33.084471Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df_select=df.drop(['Class'],axis=1)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-08-16T07:21:33.086971Z","iopub.execute_input":"2022-08-16T07:21:33.087434Z","iopub.status.idle":"2022-08-16T07:21:33.128262Z","shell.execute_reply.started":"2022-08-16T07:21:33.087393Z","shell.execute_reply":"2022-08-16T07:21:33.126772Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"features=np.array(df_select)\nlabel=np.array(df_fraud)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-16T07:21:33.130172Z","iopub.execute_input":"2022-08-16T07:21:33.131106Z","iopub.status.idle":"2022-08-16T07:21:33.172670Z","shell.execute_reply.started":"2022-08-16T07:21:33.131054Z","shell.execute_reply":"2022-08-16T07:21:33.171374Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nfrom collections import Counter\nfrom matplotlib import pyplot\nfrom numpy import where\noversample = SMOTE()\nX_r, y = oversample.fit_resample(features, label)\n# summarize the new class distribution\ncounter = Counter(y)\nprint(counter)\n# scatter plot of examples by class label\nfor label, _ in counter.items():\n    row_ix = where(y == label)[0]","metadata":{"execution":{"iopub.status.busy":"2022-08-16T07:21:33.174610Z","iopub.execute_input":"2022-08-16T07:21:33.175126Z","iopub.status.idle":"2022-08-16T07:21:34.120644Z","shell.execute_reply.started":"2022-08-16T07:21:33.175077Z","shell.execute_reply":"2022-08-16T07:21:34.119357Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Counter({0: 284315, 1: 284315})\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nX_r2 = StandardScaler().fit_transform(X_r)","metadata":{"execution":{"iopub.status.busy":"2022-08-16T07:21:34.122347Z","iopub.execute_input":"2022-08-16T07:21:34.122704Z","iopub.status.idle":"2022-08-16T07:21:34.419848Z","shell.execute_reply.started":"2022-08-16T07:21:34.122670Z","shell.execute_reply":"2022-08-16T07:21:34.418825Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"X_r2.shape","metadata":{"execution":{"iopub.status.busy":"2022-08-16T07:21:34.421732Z","iopub.execute_input":"2022-08-16T07:21:34.422175Z","iopub.status.idle":"2022-08-16T07:21:34.429874Z","shell.execute_reply.started":"2022-08-16T07:21:34.422131Z","shell.execute_reply":"2022-08-16T07:21:34.428734Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(568630, 30)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train,X_test,y_train,y_test = train_test_split(X_r2, y, test_size=0.3)\nX_train_tensors = Variable(torch.Tensor(X_train))\nX_test_tensors = Variable(torch.Tensor(X_test))\n\ny_train_tensors = Variable(torch.Tensor(y_train))\ny_test_tensors = Variable(torch.Tensor(y_test)) ","metadata":{"execution":{"iopub.status.busy":"2022-08-16T07:21:34.435895Z","iopub.execute_input":"2022-08-16T07:21:34.436255Z","iopub.status.idle":"2022-08-16T07:21:34.584004Z","shell.execute_reply.started":"2022-08-16T07:21:34.436222Z","shell.execute_reply":"2022-08-16T07:21:34.582777Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"X_train_tensors_final = torch.reshape(X_train_tensors,   (X_train_tensors.shape[0],1, X_train_tensors.shape[1]))\n\ny_train_tensors_final = torch.reshape(y_train_tensors,   (y_train_tensors.shape[0],1))\n\nX_test_tensors_final = torch.reshape(X_test_tensors,  (X_test_tensors.shape[0],1, X_test_tensors.shape[1])) \ny_test_tensors_final = torch.reshape(y_test_tensors,   (y_test_tensors.shape[0],1))","metadata":{"execution":{"iopub.status.busy":"2022-08-16T07:21:34.585504Z","iopub.execute_input":"2022-08-16T07:21:34.585840Z","iopub.status.idle":"2022-08-16T07:21:34.592113Z","shell.execute_reply.started":"2022-08-16T07:21:34.585809Z","shell.execute_reply":"2022-08-16T07:21:34.590887Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"X_train_tensors_final","metadata":{"execution":{"iopub.status.busy":"2022-08-16T07:21:34.593657Z","iopub.execute_input":"2022-08-16T07:21:34.594088Z","iopub.status.idle":"2022-08-16T07:21:34.611977Z","shell.execute_reply.started":"2022-08-16T07:21:34.594053Z","shell.execute_reply":"2022-08-16T07:21:34.611012Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"tensor([[[-1.7339,  0.2444, -0.1495,  ..., -0.3777,  0.5057, -0.4080]],\n\n        [[-0.3653,  0.5116, -0.0787,  ...,  0.5295,  0.6380, -0.4158]],\n\n        [[ 0.6165,  0.8445, -0.5111,  ..., -0.1028, -0.2338, -0.4151]],\n\n        ...,\n\n        [[-0.3357,  0.2607, -0.8788,  ...,  0.0821, -0.1967, -0.2256]],\n\n        [[ 0.4927,  0.8468, -0.4697,  ..., -0.2072, -0.2881, -0.2907]],\n\n        [[-0.1902, -0.1067, -0.6035,  ...,  0.5028,  0.0612, -0.4284]]])"},"metadata":{}}]},{"cell_type":"code","source":"print(\"Training Shape\", X_train_tensors_final.shape, y_train_tensors_final.shape)\nprint(\"Testing Shape\", X_test_tensors_final.shape, y_test_tensors.shape) \n","metadata":{"execution":{"iopub.status.busy":"2022-08-16T07:21:34.613063Z","iopub.execute_input":"2022-08-16T07:21:34.613581Z","iopub.status.idle":"2022-08-16T07:21:34.620250Z","shell.execute_reply.started":"2022-08-16T07:21:34.613540Z","shell.execute_reply":"2022-08-16T07:21:34.619039Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Training Shape torch.Size([398041, 1, 30]) torch.Size([398041, 1])\nTesting Shape torch.Size([170589, 1, 30]) torch.Size([170589])\n","output_type":"stream"}]},{"cell_type":"code","source":"device=torch.device('cuda')\ndef get_lstm_params(vocab_size, num_hiddens, device):\n    num_inputs = num_outputs = vocab_size\n\n    def normal(shape):\n        return torch.randn(size=shape, device=device)*0.01\n\n    def three():\n        return (normal((num_inputs, num_hiddens)),\n                normal((num_hiddens, num_hiddens)),\n                torch.zeros(num_hiddens, device=device))\n\n    W_xi, W_hi, b_i = three()  \n    W_xf, W_hf, b_f = three()  \n    W_xo, W_ho, b_o = three()  \n    W_xc, W_hc, b_c = three()  \n\n    W_hq = normal((num_hiddens, num_outputs))\n    b_q = torch.zeros(num_outputs, device=device)\n\n    params = [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc,\n              b_c, W_hq, b_q]\n    for param in params:\n        param.requires_grad_(True)\n    return params\n\ndef init_lstm_state(batch_size, num_hiddens, device):\n    return (torch.zeros((batch_size, num_hiddens), device=device),\n            torch.zeros((batch_size, num_hiddens), device=device))\n\ndef lstm(inputs, state, params):\n    [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c,\n     W_hq, b_q] = params\n    (H, C) = state\n    outputs = []\n    for X in inputs:\n        I = torch.sigmoid((X @ W_xi) + (H @ W_hi) + b_i)\n        F = torch.sigmoid((X @ W_xf) + (H @ W_hf) + b_f)\n        O = torch.sigmoid((X @ W_xo) + (H @ W_ho) + b_o)\n        C_tilda = torch.tanh((X @ W_xc) + (H @ W_hc) + b_c)\n        C = F * C + I * C_tilda\n        H = O * torch.tanh(C)\n        Y = (H @ W_hq) + b_q\n        outputs.append(Y)\n    return torch.cat(outputs, dim=0), (H, C)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-16T07:21:34.621519Z","iopub.execute_input":"2022-08-16T07:21:34.621958Z","iopub.status.idle":"2022-08-16T07:21:34.639877Z","shell.execute_reply.started":"2022-08-16T07:21:34.621914Z","shell.execute_reply":"2022-08-16T07:21:34.638570Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nclass LSTM1(nn.Module):\n    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length):\n        super(LSTM1, self).__init__()\n        self.num_classes = num_classes \n        self.num_layers = num_layers \n        self.input_size = input_size \n        self.hidden_size = hidden_size\n        self.seq_length = seq_length\n\n        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n                          num_layers=num_layers, batch_first=True) \n        self.fc_1 =  nn.Linear(hidden_size, 128) \n        self.fc = nn.Linear(128, num_classes) \n\n        #self.sigm = nn.Sigmoid()\n        self.relu = nn.ReLU()\n    \n    def forward(self,x):\n        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size,device=x.device)) #hidden state\n        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size,device=x.device)) #internal state\n        # Propagate input through LSTM\n        output, (hn, cn) = self.lstm(x, (h_0, c_0))\n        \n        hn = hn.view(-1, self.hidden_size) \n        out = self.relu(hn)\n        out = self.fc_1(out) \n        out = self.relu(out) \n        out = self.fc(out) \n        \n        return out\n","metadata":{"execution":{"iopub.status.busy":"2022-08-16T07:21:34.641419Z","iopub.execute_input":"2022-08-16T07:21:34.642420Z","iopub.status.idle":"2022-08-16T07:21:34.656952Z","shell.execute_reply.started":"2022-08-16T07:21:34.642370Z","shell.execute_reply":"2022-08-16T07:21:34.655748Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"\nh_0 = Variable(torch.zeros(2, X_train_tensors_final.size(0), 7)) #hidden state\nh_0.shape","metadata":{"execution":{"iopub.status.busy":"2022-08-16T07:21:34.658497Z","iopub.execute_input":"2022-08-16T07:21:34.659643Z","iopub.status.idle":"2022-08-16T07:21:34.686099Z","shell.execute_reply.started":"2022-08-16T07:21:34.659586Z","shell.execute_reply":"2022-08-16T07:21:34.684969Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"torch.Size([2, 398041, 7])"},"metadata":{}}]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nclass MyModel(nn.Module):\n    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length):\n        super(MyModel, self).__init__()\n        self.num_classes = num_classes #number of classes\n        self.num_layers = num_layers #number of layers\n        self.input_size = input_size #input size\n        self.hidden_size = hidden_size #hidden state\n        self.seq_length = seq_length #sequence length\n        \n        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n                          num_layers=num_layers, batch_first=True)\n        self.label = nn.Linear(hidden_size, num_classes)\n\n\n    def forward(self,x):\n\n\n        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size,device=x.device))\n        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size,device=x.device))\n\n\n        output, (final_hidden_state, final_cell_state) = self.lstm(x, (h_0, c_0))\n        final_hidden_state = final_hidden_state.view(-1, self.hidden_size)\n\n        return self.label(final_hidden_state) ","metadata":{"execution":{"iopub.status.busy":"2022-08-16T07:21:34.687765Z","iopub.execute_input":"2022-08-16T07:21:34.688489Z","iopub.status.idle":"2022-08-16T07:21:34.698957Z","shell.execute_reply.started":"2022-08-16T07:21:34.688444Z","shell.execute_reply":"2022-08-16T07:21:34.698021Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"X_train_tensors_final.size","metadata":{"execution":{"iopub.status.busy":"2022-08-16T07:21:34.700539Z","iopub.execute_input":"2022-08-16T07:21:34.701255Z","iopub.status.idle":"2022-08-16T07:21:34.717565Z","shell.execute_reply.started":"2022-08-16T07:21:34.701210Z","shell.execute_reply":"2022-08-16T07:21:34.716213Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"<function Tensor.size>"},"metadata":{}}]},{"cell_type":"code","source":"num_epochs = 30\nlearning_rate = 0.01\n\ninput_size = 30\nhidden_size = 7\nnum_layers = 1\n\nnum_classes = 1  \nmodel = LSTM1(num_classes, input_size, hidden_size, num_layers, X_train_tensors_final.shape[1]) #our lstm class","metadata":{"execution":{"iopub.status.busy":"2022-08-16T07:21:34.719106Z","iopub.execute_input":"2022-08-16T07:21:34.719767Z","iopub.status.idle":"2022-08-16T07:21:34.730942Z","shell.execute_reply.started":"2022-08-16T07:21:34.719725Z","shell.execute_reply":"2022-08-16T07:21:34.730060Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"criterion = torch.nn.MSELoss().cuda() if torch.cuda.is_available() else torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) ","metadata":{"execution":{"iopub.status.busy":"2022-08-16T07:21:34.732375Z","iopub.execute_input":"2022-08-16T07:21:34.733045Z","iopub.status.idle":"2022-08-16T07:21:34.740530Z","shell.execute_reply.started":"2022-08-16T07:21:34.733010Z","shell.execute_reply":"2022-08-16T07:21:34.739423Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"y_train_tensors_final.shape","metadata":{"execution":{"iopub.status.busy":"2022-08-16T07:21:34.741988Z","iopub.execute_input":"2022-08-16T07:21:34.742596Z","iopub.status.idle":"2022-08-16T07:21:34.757123Z","shell.execute_reply.started":"2022-08-16T07:21:34.742559Z","shell.execute_reply":"2022-08-16T07:21:34.755787Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"torch.Size([398041, 1])"},"metadata":{}}]},{"cell_type":"code","source":"print(X_train_tensors_final.shape)\nprint(y_train_tensors_final.shape)\nX_test_tensors_final\ny_test_tensors_final","metadata":{"execution":{"iopub.status.busy":"2022-08-16T07:21:34.758569Z","iopub.execute_input":"2022-08-16T07:21:34.759423Z","iopub.status.idle":"2022-08-16T07:21:34.774392Z","shell.execute_reply.started":"2022-08-16T07:21:34.759374Z","shell.execute_reply":"2022-08-16T07:21:34.772813Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"torch.Size([398041, 1, 30])\ntorch.Size([398041, 1])\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"tensor([[1.],\n        [0.],\n        [1.],\n        ...,\n        [1.],\n        [1.],\n        [0.]])"},"metadata":{}}]},{"cell_type":"code","source":"\noutputs=model(X_train_tensors_final)\n#loss = criterion(outputs, y_train_tensors_final)","metadata":{"execution":{"iopub.status.busy":"2022-08-16T07:21:34.775619Z","iopub.execute_input":"2022-08-16T07:21:34.776662Z","iopub.status.idle":"2022-08-16T07:21:36.128757Z","shell.execute_reply.started":"2022-08-16T07:21:34.776624Z","shell.execute_reply":"2022-08-16T07:21:36.123142Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"outputs.shape","metadata":{"execution":{"iopub.status.busy":"2022-08-16T07:21:36.140017Z","iopub.execute_input":"2022-08-16T07:21:36.143325Z","iopub.status.idle":"2022-08-16T07:21:36.177182Z","shell.execute_reply.started":"2022-08-16T07:21:36.142788Z","shell.execute_reply":"2022-08-16T07:21:36.173696Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"torch.Size([398041, 1])"},"metadata":{}}]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nfor epoch in range(num_epochs):\n  outputs = model(X_train_tensors_final).to(device)\n #forward pass\n  optimizer.zero_grad() #caluclate the gradient, manually setting to 0\n \n  # obtain the loss function\n  loss = criterion(outputs, y_train_tensors_final.to(device))\n \n  loss.backward()\n \n  optimizer.step() \n  if epoch % 10 == 0:\n    #scores = outputs.evaluate(X_test_tensors, Y_test_tensors, verbose=0)\n    print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item())) \n    ","metadata":{"execution":{"iopub.status.busy":"2022-08-16T07:21:36.186323Z","iopub.execute_input":"2022-08-16T07:21:36.189341Z","iopub.status.idle":"2022-08-16T07:22:15.119397Z","shell.execute_reply.started":"2022-08-16T07:21:36.189035Z","shell.execute_reply":"2022-08-16T07:22:15.117625Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Epoch: 0, loss: 0.59293\nEpoch: 10, loss: 0.14926\nEpoch: 20, loss: 0.07860\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model.state_dict(), \"/kaggle/working/w.pth\")","metadata":{"execution":{"iopub.status.busy":"2022-08-16T07:22:15.122060Z","iopub.execute_input":"2022-08-16T07:22:15.122625Z","iopub.status.idle":"2022-08-16T07:22:15.134323Z","shell.execute_reply.started":"2022-08-16T07:22:15.122565Z","shell.execute_reply":"2022-08-16T07:22:15.133258Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"\n# Load the model that we saved at the end of the training loop \nmodel = LSTM1(num_classes, input_size, hidden_size, num_layers, X_train_tensors_final.shape[1])\npath = \"w.pth\" \nmodel.load_state_dict(torch.load(path)) \n\nrunning_accuracy = 0 \ntotal = 0 \n\nmodel\n    ","metadata":{"execution":{"iopub.status.busy":"2022-08-16T07:22:15.135969Z","iopub.execute_input":"2022-08-16T07:22:15.136430Z","iopub.status.idle":"2022-08-16T07:22:15.155585Z","shell.execute_reply.started":"2022-08-16T07:22:15.136389Z","shell.execute_reply":"2022-08-16T07:22:15.154241Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"LSTM1(\n  (lstm): LSTM(30, 7, batch_first=True)\n  (fc_1): Linear(in_features=7, out_features=128, bias=True)\n  (fc): Linear(in_features=128, out_features=1, bias=True)\n  (relu): ReLU()\n)"},"metadata":{}}]},{"cell_type":"code","source":"y_test_tensors_final","metadata":{"execution":{"iopub.status.busy":"2022-08-16T07:22:15.161532Z","iopub.execute_input":"2022-08-16T07:22:15.161875Z","iopub.status.idle":"2022-08-16T07:22:15.169499Z","shell.execute_reply.started":"2022-08-16T07:22:15.161843Z","shell.execute_reply":"2022-08-16T07:22:15.168546Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"tensor([[1.],\n        [0.],\n        [1.],\n        ...,\n        [1.],\n        [1.],\n        [0.]])"},"metadata":{}}]},{"cell_type":"code","source":"m = nn.Softmax(dim=1)\ninput1 = torch.randn(2, 3)\nm(input1)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-16T07:22:15.171015Z","iopub.execute_input":"2022-08-16T07:22:15.171763Z","iopub.status.idle":"2022-08-16T07:22:15.183014Z","shell.execute_reply.started":"2022-08-16T07:22:15.171728Z","shell.execute_reply":"2022-08-16T07:22:15.182178Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"tensor([[0.1152, 0.0879, 0.7969],\n        [0.1255, 0.2218, 0.6527]])"},"metadata":{}}]},{"cell_type":"code","source":"X_test_tensors_final.shape","metadata":{"execution":{"iopub.status.busy":"2022-08-16T07:22:15.184691Z","iopub.execute_input":"2022-08-16T07:22:15.185378Z","iopub.status.idle":"2022-08-16T07:22:15.192422Z","shell.execute_reply.started":"2022-08-16T07:22:15.185341Z","shell.execute_reply":"2022-08-16T07:22:15.191492Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"torch.Size([170589, 1, 30])"},"metadata":{}}]},{"cell_type":"code","source":"model(X_test_tensors_final)","metadata":{"execution":{"iopub.status.busy":"2022-08-16T07:22:15.194240Z","iopub.execute_input":"2022-08-16T07:22:15.195026Z","iopub.status.idle":"2022-08-16T07:22:15.363338Z","shell.execute_reply.started":"2022-08-16T07:22:15.194981Z","shell.execute_reply":"2022-08-16T07:22:15.362314Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"tensor([[0.4948],\n        [0.1551],\n        [0.7121],\n        ...,\n        [0.8907],\n        [0.4395],\n        [0.0827]], grad_fn=<AddmmBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"y_pred_tag =torch.round(model(X_test_tensors_final))","metadata":{"execution":{"iopub.status.busy":"2022-08-16T07:22:15.364665Z","iopub.execute_input":"2022-08-16T07:22:15.364979Z","iopub.status.idle":"2022-08-16T07:22:15.525538Z","shell.execute_reply.started":"2022-08-16T07:22:15.364950Z","shell.execute_reply":"2022-08-16T07:22:15.524543Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"y_pred_tag","metadata":{"execution":{"iopub.status.busy":"2022-08-16T07:22:15.527110Z","iopub.execute_input":"2022-08-16T07:22:15.527806Z","iopub.status.idle":"2022-08-16T07:22:15.536430Z","shell.execute_reply.started":"2022-08-16T07:22:15.527760Z","shell.execute_reply":"2022-08-16T07:22:15.535270Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"tensor([[0.],\n        [0.],\n        [1.],\n        ...,\n        [1.],\n        [0.],\n        [0.]], grad_fn=<RoundBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"y_test_tensors_final","metadata":{"execution":{"iopub.status.busy":"2022-08-16T07:22:15.537954Z","iopub.execute_input":"2022-08-16T07:22:15.539261Z","iopub.status.idle":"2022-08-16T07:22:15.548812Z","shell.execute_reply.started":"2022-08-16T07:22:15.539188Z","shell.execute_reply":"2022-08-16T07:22:15.547599Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"tensor([[1.],\n        [0.],\n        [1.],\n        ...,\n        [1.],\n        [1.],\n        [0.]])"},"metadata":{}}]},{"cell_type":"code","source":"y_pred_tag[0]!=y_test_tensors_final[0]","metadata":{"execution":{"iopub.status.busy":"2022-08-16T07:22:15.552450Z","iopub.execute_input":"2022-08-16T07:22:15.552892Z","iopub.status.idle":"2022-08-16T07:22:15.563698Z","shell.execute_reply.started":"2022-08-16T07:22:15.552847Z","shell.execute_reply":"2022-08-16T07:22:15.562256Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"tensor([True])"},"metadata":{}}]},{"cell_type":"code","source":"k=0\nfor i in range(0,y_pred_tag.shape[0]):\n    if y_pred_tag[i]==y_test_tensors_final[i]:\n        k=k+1","metadata":{"execution":{"iopub.status.busy":"2022-08-16T07:22:15.565531Z","iopub.execute_input":"2022-08-16T07:22:15.566170Z","iopub.status.idle":"2022-08-16T07:22:16.664451Z","shell.execute_reply.started":"2022-08-16T07:22:15.566133Z","shell.execute_reply":"2022-08-16T07:22:16.663252Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"print('accuracy:',k/y_pred_tag.shape[0])","metadata":{"execution":{"iopub.status.busy":"2022-08-16T07:22:16.686004Z","iopub.execute_input":"2022-08-16T07:22:16.687089Z","iopub.status.idle":"2022-08-16T07:22:16.693303Z","shell.execute_reply.started":"2022-08-16T07:22:16.687045Z","shell.execute_reply":"2022-08-16T07:22:16.691785Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"accuracy: 0.9432378406579557\n","output_type":"stream"}]}]}